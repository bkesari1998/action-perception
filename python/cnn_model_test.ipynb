{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "\n",
    "from model import CNN\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageFolder(root=\"../evaluation\",\n",
    "        transform=transforms.Compose([transforms.ToTensor()])\n",
    ")\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = CNN(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.302666187286377, Accuracy: 0.10000000149011612\n",
      "Loss: 2.3024590015411377, Accuracy: 0.10000000149011612\n",
      "Loss: 2.3022613525390625, Accuracy: 0.10000000149011612\n",
      "Loss: 2.30204439163208, Accuracy: 0.20000000298023224\n",
      "Loss: 2.3017919063568115, Accuracy: 0.10000000149011612\n",
      "Loss: 2.3015224933624268, Accuracy: 0.20000000298023224\n",
      "Loss: 2.3012149333953857, Accuracy: 0.10000000149011612\n",
      "Loss: 2.300858497619629, Accuracy: 0.30000001192092896\n",
      "Loss: 2.300447463989258, Accuracy: 0.10000000149011612\n",
      "Loss: 2.299970865249634, Accuracy: 0.30000001192092896\n",
      "Loss: 2.2994284629821777, Accuracy: 0.20000000298023224\n",
      "Loss: 2.298795223236084, Accuracy: 0.20000000298023224\n",
      "Loss: 2.2980704307556152, Accuracy: 0.20000000298023224\n",
      "Loss: 2.297236919403076, Accuracy: 0.20000000298023224\n",
      "Loss: 2.296281576156616, Accuracy: 0.20000000298023224\n",
      "Loss: 2.2951714992523193, Accuracy: 0.20000000298023224\n",
      "Loss: 2.29390549659729, Accuracy: 0.20000000298023224\n",
      "Loss: 2.292452335357666, Accuracy: 0.20000000298023224\n",
      "Loss: 2.290799140930176, Accuracy: 0.20000000298023224\n",
      "Loss: 2.2889373302459717, Accuracy: 0.20000000298023224\n",
      "Loss: 2.2868902683258057, Accuracy: 0.20000000298023224\n",
      "Loss: 2.284602642059326, Accuracy: 0.20000000298023224\n",
      "Loss: 2.282042980194092, Accuracy: 0.20000000298023224\n",
      "Loss: 2.2791543006896973, Accuracy: 0.20000000298023224\n",
      "Loss: 2.2759766578674316, Accuracy: 0.20000000298023224\n",
      "Loss: 2.2723946571350098, Accuracy: 0.20000000298023224\n",
      "Loss: 2.2684073448181152, Accuracy: 0.30000001192092896\n",
      "Loss: 2.264024496078491, Accuracy: 0.30000001192092896\n",
      "Loss: 2.259286880493164, Accuracy: 0.30000001192092896\n",
      "Loss: 2.2540574073791504, Accuracy: 0.30000001192092896\n",
      "Loss: 2.248344659805298, Accuracy: 0.30000001192092896\n",
      "Loss: 2.2422289848327637, Accuracy: 0.30000001192092896\n",
      "Loss: 2.235487222671509, Accuracy: 0.4000000059604645\n",
      "Loss: 2.2285990715026855, Accuracy: 0.30000001192092896\n",
      "Loss: 2.2209014892578125, Accuracy: 0.4000000059604645\n",
      "Loss: 2.213259220123291, Accuracy: 0.4000000059604645\n",
      "Loss: 2.2044923305511475, Accuracy: 0.4000000059604645\n",
      "Loss: 2.1956076622009277, Accuracy: 0.4000000059604645\n",
      "Loss: 2.1857974529266357, Accuracy: 0.4000000059604645\n",
      "Loss: 2.176328182220459, Accuracy: 0.4000000059604645\n",
      "Loss: 2.1658949851989746, Accuracy: 0.4000000059604645\n",
      "Loss: 2.155930280685425, Accuracy: 0.4000000059604645\n",
      "Loss: 2.14447021484375, Accuracy: 0.4000000059604645\n",
      "Loss: 2.1340866088867188, Accuracy: 0.4000000059604645\n",
      "Loss: 2.1226773262023926, Accuracy: 0.4000000059604645\n",
      "Loss: 2.112285614013672, Accuracy: 0.4000000059604645\n",
      "Loss: 2.100560426712036, Accuracy: 0.5\n",
      "Loss: 2.0899319648742676, Accuracy: 0.5\n",
      "Loss: 2.0779330730438232, Accuracy: 0.5\n",
      "Loss: 2.0675535202026367, Accuracy: 0.5\n",
      "Loss: 2.054870843887329, Accuracy: 0.6000000238418579\n",
      "Loss: 2.0446135997772217, Accuracy: 0.6000000238418579\n",
      "Loss: 2.031695604324341, Accuracy: 0.6000000238418579\n",
      "Loss: 2.0211434364318848, Accuracy: 0.6000000238418579\n",
      "Loss: 2.009202003479004, Accuracy: 0.6000000238418579\n",
      "Loss: 1.9992479085922241, Accuracy: 0.6000000238418579\n",
      "Loss: 1.9875284433364868, Accuracy: 0.6000000238418579\n",
      "Loss: 1.9777908325195312, Accuracy: 0.6000000238418579\n",
      "Loss: 1.9676284790039062, Accuracy: 0.6000000238418579\n",
      "Loss: 1.9589725732803345, Accuracy: 0.6000000238418579\n",
      "Loss: 1.9492695331573486, Accuracy: 0.6000000238418579\n",
      "Loss: 1.9410035610198975, Accuracy: 0.6000000238418579\n",
      "Loss: 1.932146668434143, Accuracy: 0.6000000238418579\n",
      "Loss: 1.925463318824768, Accuracy: 0.6000000238418579\n",
      "Loss: 1.917210340499878, Accuracy: 0.6000000238418579\n",
      "Loss: 1.91152024269104, Accuracy: 0.6000000238418579\n",
      "Loss: 1.9039983749389648, Accuracy: 0.6000000238418579\n",
      "Loss: 1.8988702297210693, Accuracy: 0.6000000238418579\n",
      "Loss: 1.8916479349136353, Accuracy: 0.6000000238418579\n",
      "Loss: 1.8864223957061768, Accuracy: 0.6000000238418579\n",
      "Loss: 1.8794463872909546, Accuracy: 0.6000000238418579\n",
      "Loss: 1.874250054359436, Accuracy: 0.6000000238418579\n",
      "Loss: 1.8679168224334717, Accuracy: 0.6000000238418579\n",
      "Loss: 1.8632962703704834, Accuracy: 0.6000000238418579\n",
      "Loss: 1.857208251953125, Accuracy: 0.6000000238418579\n",
      "Loss: 1.8529876470565796, Accuracy: 0.699999988079071\n",
      "Loss: 1.8471800088882446, Accuracy: 0.6000000238418579\n",
      "Loss: 1.842588186264038, Accuracy: 0.699999988079071\n",
      "Loss: 1.8367424011230469, Accuracy: 0.6000000238418579\n",
      "Loss: 1.8314964771270752, Accuracy: 0.699999988079071\n",
      "Loss: 1.8261827230453491, Accuracy: 0.699999988079071\n",
      "Loss: 1.821393370628357, Accuracy: 0.699999988079071\n",
      "Loss: 1.8164236545562744, Accuracy: 0.699999988079071\n",
      "Loss: 1.8125324249267578, Accuracy: 0.699999988079071\n",
      "Loss: 1.8083648681640625, Accuracy: 0.699999988079071\n",
      "Loss: 1.8044707775115967, Accuracy: 0.699999988079071\n",
      "Loss: 1.8024749755859375, Accuracy: 0.699999988079071\n",
      "Loss: 1.7980434894561768, Accuracy: 0.800000011920929\n",
      "Loss: 1.7987388372421265, Accuracy: 0.699999988079071\n",
      "Loss: 1.7931197881698608, Accuracy: 0.800000011920929\n",
      "Loss: 1.795098900794983, Accuracy: 0.699999988079071\n",
      "Loss: 1.7886749505996704, Accuracy: 0.800000011920929\n",
      "Loss: 1.7911704778671265, Accuracy: 0.699999988079071\n",
      "Loss: 1.7843787670135498, Accuracy: 0.800000011920929\n",
      "Loss: 1.7882312536239624, Accuracy: 0.699999988079071\n",
      "Loss: 1.7808361053466797, Accuracy: 0.800000011920929\n",
      "Loss: 1.785652756690979, Accuracy: 0.699999988079071\n",
      "Loss: 1.7776647806167603, Accuracy: 0.800000011920929\n",
      "Loss: 1.7831363677978516, Accuracy: 0.699999988079071\n",
      "Loss: 1.774588942527771, Accuracy: 0.800000011920929\n",
      "Loss: 1.7806928157806396, Accuracy: 0.699999988079071\n",
      "Loss: 1.7717704772949219, Accuracy: 0.800000011920929\n",
      "Loss: 1.7785238027572632, Accuracy: 0.699999988079071\n",
      "Loss: 1.7691600322723389, Accuracy: 0.800000011920929\n",
      "Loss: 1.7764791250228882, Accuracy: 0.699999988079071\n",
      "Loss: 1.7665704488754272, Accuracy: 0.800000011920929\n",
      "Loss: 1.7743871212005615, Accuracy: 0.699999988079071\n",
      "Loss: 1.764084815979004, Accuracy: 0.800000011920929\n",
      "Loss: 1.7726434469223022, Accuracy: 0.699999988079071\n",
      "Loss: 1.7617626190185547, Accuracy: 0.800000011920929\n",
      "Loss: 1.7706995010375977, Accuracy: 0.699999988079071\n",
      "Loss: 1.7594501972198486, Accuracy: 0.800000011920929\n",
      "Loss: 1.7689918279647827, Accuracy: 0.699999988079071\n",
      "Loss: 1.7572832107543945, Accuracy: 0.800000011920929\n",
      "Loss: 1.7673012018203735, Accuracy: 0.699999988079071\n",
      "Loss: 1.7552248239517212, Accuracy: 0.800000011920929\n",
      "Loss: 1.7656071186065674, Accuracy: 0.699999988079071\n",
      "Loss: 1.753220558166504, Accuracy: 0.800000011920929\n",
      "Loss: 1.7640764713287354, Accuracy: 0.699999988079071\n",
      "Loss: 1.7513189315795898, Accuracy: 0.800000011920929\n",
      "Loss: 1.7624107599258423, Accuracy: 0.699999988079071\n",
      "Loss: 1.7492876052856445, Accuracy: 0.800000011920929\n",
      "Loss: 1.7609813213348389, Accuracy: 0.699999988079071\n",
      "Loss: 1.7473503351211548, Accuracy: 0.800000011920929\n",
      "Loss: 1.7596772909164429, Accuracy: 0.699999988079071\n",
      "Loss: 1.745550513267517, Accuracy: 0.8999999761581421\n",
      "Loss: 1.7582104206085205, Accuracy: 0.800000011920929\n",
      "Loss: 1.743777871131897, Accuracy: 0.8999999761581421\n",
      "Loss: 1.756879448890686, Accuracy: 0.800000011920929\n",
      "Loss: 1.7420117855072021, Accuracy: 0.8999999761581421\n",
      "Loss: 1.755566954612732, Accuracy: 0.699999988079071\n",
      "Loss: 1.7403291463851929, Accuracy: 0.800000011920929\n",
      "Loss: 1.7542991638183594, Accuracy: 0.699999988079071\n",
      "Loss: 1.7386976480484009, Accuracy: 0.800000011920929\n",
      "Loss: 1.7529128789901733, Accuracy: 0.699999988079071\n",
      "Loss: 1.7371174097061157, Accuracy: 0.800000011920929\n",
      "Loss: 1.7515777349472046, Accuracy: 0.699999988079071\n",
      "Loss: 1.735551118850708, Accuracy: 0.800000011920929\n",
      "Loss: 1.7502187490463257, Accuracy: 0.699999988079071\n",
      "Loss: 1.733994722366333, Accuracy: 0.800000011920929\n",
      "Loss: 1.7489023208618164, Accuracy: 0.699999988079071\n",
      "Loss: 1.73245108127594, Accuracy: 0.800000011920929\n",
      "Loss: 1.7475776672363281, Accuracy: 0.699999988079071\n",
      "Loss: 1.7309753894805908, Accuracy: 0.800000011920929\n",
      "Loss: 1.7463312149047852, Accuracy: 0.699999988079071\n",
      "Loss: 1.7295516729354858, Accuracy: 0.800000011920929\n",
      "Loss: 1.7449657917022705, Accuracy: 0.699999988079071\n",
      "Loss: 1.728092908859253, Accuracy: 0.800000011920929\n",
      "Loss: 1.7437288761138916, Accuracy: 0.699999988079071\n",
      "Loss: 1.7267014980316162, Accuracy: 0.800000011920929\n",
      "Loss: 1.7424829006195068, Accuracy: 0.699999988079071\n",
      "Loss: 1.7252025604248047, Accuracy: 0.800000011920929\n",
      "Loss: 1.7413661479949951, Accuracy: 0.699999988079071\n",
      "Loss: 1.7238292694091797, Accuracy: 0.800000011920929\n",
      "Loss: 1.7401033639907837, Accuracy: 0.699999988079071\n",
      "Loss: 1.7224586009979248, Accuracy: 0.800000011920929\n",
      "Loss: 1.7389236688613892, Accuracy: 0.699999988079071\n",
      "Loss: 1.7211081981658936, Accuracy: 0.800000011920929\n",
      "Loss: 1.7376505136489868, Accuracy: 0.699999988079071\n",
      "Loss: 1.7196824550628662, Accuracy: 0.800000011920929\n",
      "Loss: 1.7363992929458618, Accuracy: 0.699999988079071\n",
      "Loss: 1.7182109355926514, Accuracy: 0.800000011920929\n",
      "Loss: 1.7352440357208252, Accuracy: 0.699999988079071\n",
      "Loss: 1.7167787551879883, Accuracy: 0.800000011920929\n",
      "Loss: 1.7341617345809937, Accuracy: 0.699999988079071\n",
      "Loss: 1.7153955698013306, Accuracy: 0.800000011920929\n",
      "Loss: 1.73294997215271, Accuracy: 0.699999988079071\n",
      "Loss: 1.7140064239501953, Accuracy: 0.800000011920929\n",
      "Loss: 1.7317091226577759, Accuracy: 0.699999988079071\n",
      "Loss: 1.7126092910766602, Accuracy: 0.800000011920929\n",
      "Loss: 1.7305103540420532, Accuracy: 0.800000011920929\n",
      "Loss: 1.7112830877304077, Accuracy: 0.800000011920929\n",
      "Loss: 1.7291595935821533, Accuracy: 0.800000011920929\n",
      "Loss: 1.709826111793518, Accuracy: 0.800000011920929\n",
      "Loss: 1.7280349731445312, Accuracy: 0.800000011920929\n",
      "Loss: 1.7084362506866455, Accuracy: 0.800000011920929\n",
      "Loss: 1.7268848419189453, Accuracy: 0.800000011920929\n",
      "Loss: 1.7071813344955444, Accuracy: 0.800000011920929\n",
      "Loss: 1.7256377935409546, Accuracy: 0.800000011920929\n",
      "Loss: 1.705793023109436, Accuracy: 0.800000011920929\n",
      "Loss: 1.7243064641952515, Accuracy: 0.800000011920929\n",
      "Loss: 1.7044785022735596, Accuracy: 0.800000011920929\n",
      "Loss: 1.7230567932128906, Accuracy: 0.800000011920929\n",
      "Loss: 1.7031526565551758, Accuracy: 0.800000011920929\n",
      "Loss: 1.7217212915420532, Accuracy: 0.800000011920929\n",
      "Loss: 1.7018327713012695, Accuracy: 0.800000011920929\n",
      "Loss: 1.720467209815979, Accuracy: 0.800000011920929\n",
      "Loss: 1.7004142999649048, Accuracy: 0.800000011920929\n",
      "Loss: 1.7191795110702515, Accuracy: 0.800000011920929\n",
      "Loss: 1.6991603374481201, Accuracy: 0.800000011920929\n",
      "Loss: 1.7180598974227905, Accuracy: 0.800000011920929\n",
      "Loss: 1.697885274887085, Accuracy: 0.8999999761581421\n",
      "Loss: 1.716473937034607, Accuracy: 0.800000011920929\n",
      "Loss: 1.696578025817871, Accuracy: 0.8999999761581421\n",
      "Loss: 1.7152847051620483, Accuracy: 0.800000011920929\n",
      "Loss: 1.695343017578125, Accuracy: 0.8999999761581421\n",
      "Loss: 1.7138950824737549, Accuracy: 0.800000011920929\n",
      "Loss: 1.6941131353378296, Accuracy: 0.8999999761581421\n",
      "Loss: 1.7126814126968384, Accuracy: 0.800000011920929\n",
      "Loss: 1.6927368640899658, Accuracy: 0.8999999761581421\n",
      "Loss: 1.7113006114959717, Accuracy: 0.800000011920929\n",
      "Loss: 1.6914781332015991, Accuracy: 0.8999999761581421\n",
      "Loss: 1.710113763809204, Accuracy: 0.800000011920929\n",
      "Loss: 1.6902574300765991, Accuracy: 0.8999999761581421\n",
      "Loss: 1.70882248878479, Accuracy: 0.800000011920929\n",
      "Loss: 1.689019799232483, Accuracy: 0.8999999761581421\n",
      "Loss: 1.7073230743408203, Accuracy: 0.800000011920929\n",
      "Loss: 1.6877717971801758, Accuracy: 0.8999999761581421\n",
      "Loss: 1.7060091495513916, Accuracy: 0.800000011920929\n",
      "Loss: 1.6865087747573853, Accuracy: 0.8999999761581421\n",
      "Loss: 1.7047265768051147, Accuracy: 0.800000011920929\n",
      "Loss: 1.6851921081542969, Accuracy: 0.8999999761581421\n",
      "Loss: 1.7033815383911133, Accuracy: 0.800000011920929\n",
      "Loss: 1.6839306354522705, Accuracy: 0.8999999761581421\n",
      "Loss: 1.702061414718628, Accuracy: 0.800000011920929\n",
      "Loss: 1.6826450824737549, Accuracy: 0.8999999761581421\n",
      "Loss: 1.7004978656768799, Accuracy: 0.800000011920929\n",
      "Loss: 1.681391716003418, Accuracy: 0.8999999761581421\n",
      "Loss: 1.69915771484375, Accuracy: 0.800000011920929\n",
      "Loss: 1.680063247680664, Accuracy: 1.0\n",
      "Loss: 1.6978448629379272, Accuracy: 0.800000011920929\n",
      "Loss: 1.6787599325180054, Accuracy: 1.0\n",
      "Loss: 1.6965948343276978, Accuracy: 0.800000011920929\n",
      "Loss: 1.6773719787597656, Accuracy: 1.0\n",
      "Loss: 1.6950485706329346, Accuracy: 0.800000011920929\n",
      "Loss: 1.6760900020599365, Accuracy: 1.0\n",
      "Loss: 1.6939891576766968, Accuracy: 0.800000011920929\n",
      "Loss: 1.6747785806655884, Accuracy: 1.0\n",
      "Loss: 1.6924850940704346, Accuracy: 0.800000011920929\n",
      "Loss: 1.6733413934707642, Accuracy: 1.0\n",
      "Loss: 1.6908918619155884, Accuracy: 0.800000011920929\n",
      "Loss: 1.672029733657837, Accuracy: 1.0\n",
      "Loss: 1.6895898580551147, Accuracy: 0.800000011920929\n",
      "Loss: 1.6705882549285889, Accuracy: 1.0\n",
      "Loss: 1.6882396936416626, Accuracy: 0.800000011920929\n",
      "Loss: 1.6692743301391602, Accuracy: 1.0\n",
      "Loss: 1.6866775751113892, Accuracy: 0.800000011920929\n",
      "Loss: 1.6678581237792969, Accuracy: 1.0\n",
      "Loss: 1.6852039098739624, Accuracy: 0.800000011920929\n",
      "Loss: 1.6664705276489258, Accuracy: 1.0\n",
      "Loss: 1.6838724613189697, Accuracy: 0.800000011920929\n",
      "Loss: 1.6650521755218506, Accuracy: 1.0\n",
      "Loss: 1.6822879314422607, Accuracy: 0.800000011920929\n",
      "Loss: 1.663633942604065, Accuracy: 1.0\n",
      "Loss: 1.6808208227157593, Accuracy: 0.800000011920929\n",
      "Loss: 1.6622040271759033, Accuracy: 1.0\n",
      "Loss: 1.679256796836853, Accuracy: 0.800000011920929\n",
      "Loss: 1.6606996059417725, Accuracy: 1.0\n",
      "Loss: 1.6778780221939087, Accuracy: 0.800000011920929\n",
      "Loss: 1.6593010425567627, Accuracy: 1.0\n",
      "Loss: 1.6764500141143799, Accuracy: 0.800000011920929\n",
      "Loss: 1.6577236652374268, Accuracy: 1.0\n",
      "Loss: 1.6748977899551392, Accuracy: 0.800000011920929\n",
      "Loss: 1.6561615467071533, Accuracy: 1.0\n",
      "Loss: 1.673358678817749, Accuracy: 0.800000011920929\n",
      "Loss: 1.6546541452407837, Accuracy: 1.0\n",
      "Loss: 1.671987533569336, Accuracy: 0.8999999761581421\n",
      "Loss: 1.6531951427459717, Accuracy: 1.0\n",
      "Loss: 1.6706607341766357, Accuracy: 0.800000011920929\n",
      "Loss: 1.6515529155731201, Accuracy: 1.0\n",
      "Loss: 1.669248342514038, Accuracy: 0.8999999761581421\n",
      "Loss: 1.650024175643921, Accuracy: 1.0\n",
      "Loss: 1.6676528453826904, Accuracy: 0.8999999761581421\n",
      "Loss: 1.648550033569336, Accuracy: 1.0\n",
      "Loss: 1.6661542654037476, Accuracy: 0.8999999761581421\n",
      "Loss: 1.6470911502838135, Accuracy: 1.0\n",
      "Loss: 1.6647393703460693, Accuracy: 0.8999999761581421\n",
      "Loss: 1.6456642150878906, Accuracy: 1.0\n",
      "Loss: 1.663191795349121, Accuracy: 0.8999999761581421\n",
      "Loss: 1.6442521810531616, Accuracy: 1.0\n",
      "Loss: 1.6618211269378662, Accuracy: 0.8999999761581421\n",
      "Loss: 1.6430034637451172, Accuracy: 1.0\n",
      "Loss: 1.6604028940200806, Accuracy: 0.8999999761581421\n",
      "Loss: 1.6416813135147095, Accuracy: 1.0\n",
      "Loss: 1.6588621139526367, Accuracy: 0.8999999761581421\n",
      "Loss: 1.640379548072815, Accuracy: 1.0\n",
      "Loss: 1.657707929611206, Accuracy: 0.8999999761581421\n",
      "Loss: 1.6391830444335938, Accuracy: 1.0\n",
      "Loss: 1.6562035083770752, Accuracy: 0.800000011920929\n",
      "Loss: 1.6379778385162354, Accuracy: 1.0\n",
      "Loss: 1.654836654663086, Accuracy: 0.800000011920929\n",
      "Loss: 1.6367475986480713, Accuracy: 1.0\n",
      "Loss: 1.6536035537719727, Accuracy: 0.800000011920929\n",
      "Loss: 1.6356277465820312, Accuracy: 1.0\n",
      "Loss: 1.6524059772491455, Accuracy: 0.800000011920929\n",
      "Loss: 1.6345126628875732, Accuracy: 1.0\n",
      "Loss: 1.6511605978012085, Accuracy: 0.800000011920929\n",
      "Loss: 1.633418083190918, Accuracy: 1.0\n",
      "Loss: 1.650233268737793, Accuracy: 0.800000011920929\n",
      "Loss: 1.6323188543319702, Accuracy: 1.0\n",
      "Loss: 1.649045705795288, Accuracy: 0.800000011920929\n",
      "Loss: 1.6312509775161743, Accuracy: 1.0\n",
      "Loss: 1.6479021310806274, Accuracy: 0.800000011920929\n",
      "Loss: 1.6301982402801514, Accuracy: 1.0\n",
      "Loss: 1.6468169689178467, Accuracy: 0.800000011920929\n",
      "Loss: 1.6291996240615845, Accuracy: 1.0\n",
      "Loss: 1.6457719802856445, Accuracy: 0.800000011920929\n",
      "Loss: 1.6282199621200562, Accuracy: 1.0\n",
      "Loss: 1.6446698904037476, Accuracy: 0.800000011920929\n",
      "Loss: 1.6272099018096924, Accuracy: 1.0\n",
      "Loss: 1.6437227725982666, Accuracy: 0.800000011920929\n",
      "Loss: 1.6262328624725342, Accuracy: 1.0\n",
      "Loss: 1.6426517963409424, Accuracy: 0.800000011920929\n",
      "Loss: 1.625280737876892, Accuracy: 1.0\n",
      "Loss: 1.6415977478027344, Accuracy: 0.800000011920929\n",
      "Loss: 1.6243584156036377, Accuracy: 1.0\n",
      "Loss: 1.640566110610962, Accuracy: 0.800000011920929\n",
      "Loss: 1.6234779357910156, Accuracy: 1.0\n",
      "Loss: 1.6396350860595703, Accuracy: 0.800000011920929\n",
      "Loss: 1.6225427389144897, Accuracy: 1.0\n",
      "Loss: 1.6385999917984009, Accuracy: 0.800000011920929\n",
      "Loss: 1.6216685771942139, Accuracy: 1.0\n",
      "Loss: 1.6376006603240967, Accuracy: 0.800000011920929\n",
      "Loss: 1.6207584142684937, Accuracy: 1.0\n",
      "Loss: 1.6366771459579468, Accuracy: 0.800000011920929\n",
      "Loss: 1.6198513507843018, Accuracy: 1.0\n",
      "Loss: 1.6357486248016357, Accuracy: 0.800000011920929\n",
      "Loss: 1.6189768314361572, Accuracy: 1.0\n",
      "Loss: 1.6347019672393799, Accuracy: 0.800000011920929\n",
      "Loss: 1.6180588006973267, Accuracy: 1.0\n",
      "Loss: 1.6337306499481201, Accuracy: 0.800000011920929\n",
      "Loss: 1.6171575784683228, Accuracy: 1.0\n",
      "Loss: 1.6326959133148193, Accuracy: 0.800000011920929\n",
      "Loss: 1.6162830591201782, Accuracy: 1.0\n",
      "Loss: 1.6318390369415283, Accuracy: 0.800000011920929\n",
      "Loss: 1.615377426147461, Accuracy: 1.0\n",
      "Loss: 1.6307590007781982, Accuracy: 0.8999999761581421\n",
      "Loss: 1.6145267486572266, Accuracy: 1.0\n",
      "Loss: 1.6296865940093994, Accuracy: 0.8999999761581421\n",
      "Loss: 1.6136735677719116, Accuracy: 1.0\n",
      "Loss: 1.628710150718689, Accuracy: 0.8999999761581421\n",
      "Loss: 1.6128298044204712, Accuracy: 1.0\n",
      "Loss: 1.6278107166290283, Accuracy: 0.8999999761581421\n",
      "Loss: 1.6119768619537354, Accuracy: 1.0\n",
      "Loss: 1.6267051696777344, Accuracy: 0.8999999761581421\n",
      "Loss: 1.6110765933990479, Accuracy: 1.0\n",
      "Loss: 1.6259040832519531, Accuracy: 0.8999999761581421\n",
      "Loss: 1.6102559566497803, Accuracy: 1.0\n",
      "Loss: 1.6248979568481445, Accuracy: 0.8999999761581421\n",
      "Loss: 1.609445571899414, Accuracy: 1.0\n",
      "Loss: 1.6239712238311768, Accuracy: 0.8999999761581421\n",
      "Loss: 1.6086463928222656, Accuracy: 1.0\n",
      "Loss: 1.6230335235595703, Accuracy: 0.8999999761581421\n",
      "Loss: 1.607873558998108, Accuracy: 1.0\n",
      "Loss: 1.622130036354065, Accuracy: 0.8999999761581421\n",
      "Loss: 1.6070940494537354, Accuracy: 1.0\n",
      "Loss: 1.6211553812026978, Accuracy: 0.8999999761581421\n",
      "Loss: 1.606327772140503, Accuracy: 1.0\n",
      "Loss: 1.6202733516693115, Accuracy: 0.8999999761581421\n",
      "Loss: 1.60555100440979, Accuracy: 1.0\n",
      "Loss: 1.6194053888320923, Accuracy: 0.8999999761581421\n",
      "Loss: 1.604798674583435, Accuracy: 1.0\n",
      "Loss: 1.6185041666030884, Accuracy: 0.8999999761581421\n",
      "Loss: 1.6040233373641968, Accuracy: 1.0\n",
      "Loss: 1.6176269054412842, Accuracy: 0.8999999761581421\n",
      "Loss: 1.6032737493515015, Accuracy: 1.0\n",
      "Loss: 1.6166938543319702, Accuracy: 0.8999999761581421\n",
      "Loss: 1.6024906635284424, Accuracy: 1.0\n",
      "Loss: 1.615898847579956, Accuracy: 0.8999999761581421\n",
      "Loss: 1.6017637252807617, Accuracy: 1.0\n",
      "Loss: 1.6150906085968018, Accuracy: 0.8999999761581421\n",
      "Loss: 1.6010596752166748, Accuracy: 1.0\n",
      "Loss: 1.6141777038574219, Accuracy: 0.8999999761581421\n",
      "Loss: 1.6002849340438843, Accuracy: 1.0\n",
      "Loss: 1.6134157180786133, Accuracy: 0.8999999761581421\n",
      "Loss: 1.599561095237732, Accuracy: 1.0\n",
      "Loss: 1.6126394271850586, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5988569259643555, Accuracy: 1.0\n",
      "Loss: 1.6117737293243408, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5981473922729492, Accuracy: 1.0\n",
      "Loss: 1.6109068393707275, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5974245071411133, Accuracy: 1.0\n",
      "Loss: 1.6101669073104858, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5967381000518799, Accuracy: 1.0\n",
      "Loss: 1.6093580722808838, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5959829092025757, Accuracy: 1.0\n",
      "Loss: 1.6086565256118774, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5952608585357666, Accuracy: 1.0\n",
      "Loss: 1.607936143875122, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5945485830307007, Accuracy: 1.0\n",
      "Loss: 1.6071884632110596, Accuracy: 0.8999999761581421\n",
      "Loss: 1.593820333480835, Accuracy: 1.0\n",
      "Loss: 1.6065289974212646, Accuracy: 0.8999999761581421\n",
      "Loss: 1.593155860900879, Accuracy: 1.0\n",
      "Loss: 1.6057941913604736, Accuracy: 0.8999999761581421\n",
      "Loss: 1.592471957206726, Accuracy: 1.0\n",
      "Loss: 1.605154037475586, Accuracy: 0.8999999761581421\n",
      "Loss: 1.591758131980896, Accuracy: 1.0\n",
      "Loss: 1.6045091152191162, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5910604000091553, Accuracy: 1.0\n",
      "Loss: 1.6038818359375, Accuracy: 0.8999999761581421\n",
      "Loss: 1.590375304222107, Accuracy: 1.0\n",
      "Loss: 1.603341817855835, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5897152423858643, Accuracy: 1.0\n",
      "Loss: 1.6026397943496704, Accuracy: 0.8999999761581421\n",
      "Loss: 1.589036226272583, Accuracy: 1.0\n",
      "Loss: 1.602120041847229, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5883876085281372, Accuracy: 1.0\n",
      "Loss: 1.6013962030410767, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5877258777618408, Accuracy: 1.0\n",
      "Loss: 1.6007696390151978, Accuracy: 0.8999999761581421\n",
      "Loss: 1.587091326713562, Accuracy: 1.0\n",
      "Loss: 1.6001627445220947, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5864518880844116, Accuracy: 1.0\n",
      "Loss: 1.5995399951934814, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5858064889907837, Accuracy: 1.0\n",
      "Loss: 1.5989643335342407, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5852024555206299, Accuracy: 1.0\n",
      "Loss: 1.5983340740203857, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5845881700515747, Accuracy: 1.0\n",
      "Loss: 1.5977442264556885, Accuracy: 0.8999999761581421\n",
      "Loss: 1.583988904953003, Accuracy: 1.0\n",
      "Loss: 1.5971055030822754, Accuracy: 0.8999999761581421\n",
      "Loss: 1.583401083946228, Accuracy: 1.0\n",
      "Loss: 1.5965380668640137, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5827953815460205, Accuracy: 1.0\n",
      "Loss: 1.595962405204773, Accuracy: 0.8999999761581421\n",
      "Loss: 1.582218050956726, Accuracy: 1.0\n",
      "Loss: 1.595316767692566, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5816547870635986, Accuracy: 1.0\n",
      "Loss: 1.5947329998016357, Accuracy: 0.8999999761581421\n",
      "Loss: 1.581082820892334, Accuracy: 1.0\n",
      "Loss: 1.5941559076309204, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5805022716522217, Accuracy: 1.0\n",
      "Loss: 1.5935823917388916, Accuracy: 0.8999999761581421\n",
      "Loss: 1.579923152923584, Accuracy: 1.0\n",
      "Loss: 1.593003273010254, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5793614387512207, Accuracy: 1.0\n",
      "Loss: 1.5924338102340698, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5787992477416992, Accuracy: 1.0\n",
      "Loss: 1.5918530225753784, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5782268047332764, Accuracy: 1.0\n",
      "Loss: 1.5912702083587646, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5776761770248413, Accuracy: 1.0\n",
      "Loss: 1.590699315071106, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5771039724349976, Accuracy: 1.0\n",
      "Loss: 1.5901309251785278, Accuracy: 0.8999999761581421\n",
      "Loss: 1.576544165611267, Accuracy: 1.0\n",
      "Loss: 1.5895562171936035, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5759718418121338, Accuracy: 1.0\n",
      "Loss: 1.5889837741851807, Accuracy: 0.8999999761581421\n",
      "Loss: 1.575433373451233, Accuracy: 1.0\n",
      "Loss: 1.5884158611297607, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5748069286346436, Accuracy: 1.0\n",
      "Loss: 1.5878362655639648, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5742353200912476, Accuracy: 1.0\n",
      "Loss: 1.587257981300354, Accuracy: 0.8999999761581421\n",
      "Loss: 1.573674201965332, Accuracy: 1.0\n",
      "Loss: 1.5866960287094116, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5730836391448975, Accuracy: 1.0\n",
      "Loss: 1.5861153602600098, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5725224018096924, Accuracy: 1.0\n",
      "Loss: 1.5855588912963867, Accuracy: 0.8999999761581421\n",
      "Loss: 1.571934461593628, Accuracy: 1.0\n",
      "Loss: 1.584961175918579, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5713374614715576, Accuracy: 1.0\n",
      "Loss: 1.5844223499298096, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5707862377166748, Accuracy: 1.0\n",
      "Loss: 1.5839102268218994, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5702261924743652, Accuracy: 1.0\n",
      "Loss: 1.583409309387207, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5696743726730347, Accuracy: 1.0\n",
      "Loss: 1.5828883647918701, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5691195726394653, Accuracy: 1.0\n",
      "Loss: 1.5823873281478882, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5685635805130005, Accuracy: 1.0\n",
      "Loss: 1.5818779468536377, Accuracy: 0.8999999761581421\n",
      "Loss: 1.567983627319336, Accuracy: 1.0\n",
      "Loss: 1.5813722610473633, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5674231052398682, Accuracy: 1.0\n",
      "Loss: 1.580851435661316, Accuracy: 0.8999999761581421\n",
      "Loss: 1.566846489906311, Accuracy: 1.0\n",
      "Loss: 1.5803459882736206, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5662262439727783, Accuracy: 1.0\n",
      "Loss: 1.5798368453979492, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5656774044036865, Accuracy: 1.0\n",
      "Loss: 1.5793426036834717, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5650564432144165, Accuracy: 1.0\n",
      "Loss: 1.578839898109436, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5644901990890503, Accuracy: 1.0\n",
      "Loss: 1.578330397605896, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5639334917068481, Accuracy: 1.0\n",
      "Loss: 1.5777966976165771, Accuracy: 0.8999999761581421\n",
      "Loss: 1.563361406326294, Accuracy: 1.0\n",
      "Loss: 1.5772985219955444, Accuracy: 0.8999999761581421\n",
      "Loss: 1.562816858291626, Accuracy: 1.0\n",
      "Loss: 1.5768104791641235, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5622646808624268, Accuracy: 1.0\n",
      "Loss: 1.576317310333252, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5617412328720093, Accuracy: 1.0\n",
      "Loss: 1.5757718086242676, Accuracy: 0.8999999761581421\n",
      "Loss: 1.561193585395813, Accuracy: 1.0\n",
      "Loss: 1.5752819776535034, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5606112480163574, Accuracy: 1.0\n",
      "Loss: 1.5748186111450195, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5600812435150146, Accuracy: 1.0\n",
      "Loss: 1.5743024349212646, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5595390796661377, Accuracy: 1.0\n",
      "Loss: 1.5738084316253662, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5589908361434937, Accuracy: 1.0\n",
      "Loss: 1.5733387470245361, Accuracy: 0.8999999761581421\n",
      "Loss: 1.558432698249817, Accuracy: 1.0\n",
      "Loss: 1.5728447437286377, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5579168796539307, Accuracy: 1.0\n",
      "Loss: 1.572371482849121, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5573800802230835, Accuracy: 1.0\n",
      "Loss: 1.5718542337417603, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5568528175354004, Accuracy: 1.0\n",
      "Loss: 1.571386456489563, Accuracy: 0.8999999761581421\n",
      "Loss: 1.556328535079956, Accuracy: 1.0\n",
      "Loss: 1.5708521604537964, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5557953119277954, Accuracy: 1.0\n",
      "Loss: 1.570373773574829, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5552657842636108, Accuracy: 1.0\n",
      "Loss: 1.5698765516281128, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5547025203704834, Accuracy: 1.0\n",
      "Loss: 1.5693153142929077, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5543162822723389, Accuracy: 1.0\n",
      "Loss: 1.5685731172561646, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5539151430130005, Accuracy: 1.0\n",
      "Loss: 1.5678809881210327, Accuracy: 0.8999999761581421\n",
      "Loss: 1.553328037261963, Accuracy: 1.0\n",
      "Loss: 1.5673034191131592, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5527422428131104, Accuracy: 1.0\n",
      "Loss: 1.566771388053894, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5522112846374512, Accuracy: 1.0\n",
      "Loss: 1.5662496089935303, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5516611337661743, Accuracy: 1.0\n",
      "Loss: 1.5657329559326172, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5510863065719604, Accuracy: 1.0\n",
      "Loss: 1.5651695728302002, Accuracy: 0.8999999761581421\n",
      "Loss: 1.550502896308899, Accuracy: 1.0\n",
      "Loss: 1.5646512508392334, Accuracy: 0.8999999761581421\n",
      "Loss: 1.549926519393921, Accuracy: 1.0\n",
      "Loss: 1.5641086101531982, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5493260622024536, Accuracy: 1.0\n",
      "Loss: 1.5635370016098022, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5486980676651, Accuracy: 1.0\n",
      "Loss: 1.5628782510757446, Accuracy: 0.8999999761581421\n",
      "Loss: 1.548084020614624, Accuracy: 1.0\n",
      "Loss: 1.5624465942382812, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5474708080291748, Accuracy: 1.0\n",
      "Loss: 1.5618757009506226, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5469372272491455, Accuracy: 1.0\n",
      "Loss: 1.5613434314727783, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5463569164276123, Accuracy: 1.0\n",
      "Loss: 1.5606939792633057, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5457803010940552, Accuracy: 1.0\n",
      "Loss: 1.5601699352264404, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5450950860977173, Accuracy: 1.0\n",
      "Loss: 1.5594369173049927, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5445468425750732, Accuracy: 1.0\n",
      "Loss: 1.5587393045425415, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5439908504486084, Accuracy: 1.0\n",
      "Loss: 1.5580852031707764, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5433276891708374, Accuracy: 1.0\n",
      "Loss: 1.5573670864105225, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5427277088165283, Accuracy: 1.0\n",
      "Loss: 1.5565075874328613, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5421310663223267, Accuracy: 1.0\n",
      "Loss: 1.5556854009628296, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5415360927581787, Accuracy: 1.0\n",
      "Loss: 1.5548884868621826, Accuracy: 0.8999999761581421\n",
      "Loss: 1.540970802307129, Accuracy: 1.0\n",
      "Loss: 1.5542409420013428, Accuracy: 0.8999999761581421\n",
      "Loss: 1.540342092514038, Accuracy: 1.0\n",
      "Loss: 1.5536805391311646, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5398566722869873, Accuracy: 1.0\n",
      "Loss: 1.5530831813812256, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5392625331878662, Accuracy: 1.0\n",
      "Loss: 1.5524330139160156, Accuracy: 0.8999999761581421\n",
      "Loss: 1.538653016090393, Accuracy: 1.0\n",
      "Loss: 1.5517809391021729, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5379643440246582, Accuracy: 1.0\n",
      "Loss: 1.5511690378189087, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5372600555419922, Accuracy: 1.0\n",
      "Loss: 1.5505528450012207, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5369963645935059, Accuracy: 1.0\n",
      "Loss: 1.5498602390289307, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5377781391143799, Accuracy: 1.0\n",
      "Loss: 1.5551809072494507, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5374338626861572, Accuracy: 1.0\n",
      "Loss: 1.5544264316558838, Accuracy: 0.8999999761581421\n",
      "Loss: 1.53780198097229, Accuracy: 1.0\n",
      "Loss: 1.5536386966705322, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5369563102722168, Accuracy: 1.0\n",
      "Loss: 1.5529695749282837, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5364607572555542, Accuracy: 1.0\n",
      "Loss: 1.5527286529541016, Accuracy: 0.8999999761581421\n",
      "Loss: 1.5361144542694092, Accuracy: 1.0\n",
      "Loss: 1.5521513223648071, Accuracy: 1.0\n",
      "Loss: 1.5360636711120605, Accuracy: 1.0\n",
      "Loss: 1.551268458366394, Accuracy: 1.0\n",
      "Loss: 1.5356372594833374, Accuracy: 1.0\n",
      "Loss: 1.5506449937820435, Accuracy: 1.0\n",
      "Loss: 1.5352274179458618, Accuracy: 1.0\n",
      "Loss: 1.5496479272842407, Accuracy: 1.0\n",
      "Loss: 1.5362637042999268, Accuracy: 1.0\n",
      "Loss: 1.5488710403442383, Accuracy: 1.0\n",
      "Loss: 1.535205602645874, Accuracy: 1.0\n",
      "Loss: 1.5484215021133423, Accuracy: 1.0\n",
      "Loss: 1.5348303318023682, Accuracy: 1.0\n",
      "Loss: 1.5479246377944946, Accuracy: 1.0\n",
      "Loss: 1.5344436168670654, Accuracy: 1.0\n",
      "Loss: 1.5470370054244995, Accuracy: 1.0\n",
      "Loss: 1.5350948572158813, Accuracy: 1.0\n",
      "Loss: 1.5462970733642578, Accuracy: 1.0\n",
      "Loss: 1.5342762470245361, Accuracy: 1.0\n",
      "Loss: 1.5461554527282715, Accuracy: 1.0\n",
      "Loss: 1.5338107347488403, Accuracy: 1.0\n",
      "Loss: 1.545586109161377, Accuracy: 1.0\n",
      "Loss: 1.533355951309204, Accuracy: 1.0\n",
      "Loss: 1.5453016757965088, Accuracy: 1.0\n",
      "Loss: 1.5329054594039917, Accuracy: 1.0\n",
      "Loss: 1.545769453048706, Accuracy: 1.0\n",
      "Loss: 1.5325504541397095, Accuracy: 1.0\n",
      "Loss: 1.5454387664794922, Accuracy: 1.0\n",
      "Loss: 1.532192587852478, Accuracy: 1.0\n",
      "Loss: 1.545038104057312, Accuracy: 1.0\n",
      "Loss: 1.5318530797958374, Accuracy: 1.0\n",
      "Loss: 1.5446757078170776, Accuracy: 1.0\n",
      "Loss: 1.5315309762954712, Accuracy: 1.0\n",
      "Loss: 1.5444142818450928, Accuracy: 1.0\n",
      "Loss: 1.531162977218628, Accuracy: 1.0\n",
      "Loss: 1.5440995693206787, Accuracy: 1.0\n",
      "Loss: 1.5308501720428467, Accuracy: 1.0\n",
      "Loss: 1.5437092781066895, Accuracy: 1.0\n",
      "Loss: 1.530576467514038, Accuracy: 1.0\n",
      "Loss: 1.5431140661239624, Accuracy: 1.0\n",
      "Loss: 1.5305759906768799, Accuracy: 1.0\n",
      "Loss: 1.5424039363861084, Accuracy: 1.0\n",
      "Loss: 1.530275583267212, Accuracy: 1.0\n",
      "Loss: 1.5420020818710327, Accuracy: 1.0\n",
      "Loss: 1.5299521684646606, Accuracy: 1.0\n",
      "Loss: 1.5413613319396973, Accuracy: 1.0\n",
      "Loss: 1.5300344228744507, Accuracy: 1.0\n",
      "Loss: 1.540814995765686, Accuracy: 1.0\n",
      "Loss: 1.5297126770019531, Accuracy: 1.0\n",
      "Loss: 1.5405480861663818, Accuracy: 1.0\n",
      "Loss: 1.529374361038208, Accuracy: 1.0\n",
      "Loss: 1.5402195453643799, Accuracy: 1.0\n",
      "Loss: 1.5290420055389404, Accuracy: 1.0\n",
      "Loss: 1.5398638248443604, Accuracy: 1.0\n",
      "Loss: 1.528699517250061, Accuracy: 1.0\n",
      "Loss: 1.5394947528839111, Accuracy: 1.0\n",
      "Loss: 1.5283739566802979, Accuracy: 1.0\n",
      "Loss: 1.5391440391540527, Accuracy: 1.0\n",
      "Loss: 1.5280938148498535, Accuracy: 1.0\n",
      "Loss: 1.538954257965088, Accuracy: 1.0\n",
      "Loss: 1.5281600952148438, Accuracy: 1.0\n",
      "Loss: 1.538576364517212, Accuracy: 1.0\n",
      "Loss: 1.527864694595337, Accuracy: 1.0\n",
      "Loss: 1.5381747484207153, Accuracy: 1.0\n",
      "Loss: 1.527808427810669, Accuracy: 1.0\n",
      "Loss: 1.5378034114837646, Accuracy: 1.0\n",
      "Loss: 1.5274728536605835, Accuracy: 1.0\n",
      "Loss: 1.537458062171936, Accuracy: 1.0\n",
      "Loss: 1.5271590948104858, Accuracy: 1.0\n",
      "Loss: 1.5370848178863525, Accuracy: 1.0\n",
      "Loss: 1.5268688201904297, Accuracy: 1.0\n",
      "Loss: 1.536757230758667, Accuracy: 1.0\n",
      "Loss: 1.5265499353408813, Accuracy: 1.0\n",
      "Loss: 1.5363935232162476, Accuracy: 1.0\n",
      "Loss: 1.5262491703033447, Accuracy: 1.0\n",
      "Loss: 1.5360009670257568, Accuracy: 1.0\n",
      "Loss: 1.5259946584701538, Accuracy: 1.0\n",
      "Loss: 1.5356236696243286, Accuracy: 1.0\n",
      "Loss: 1.5260287523269653, Accuracy: 1.0\n",
      "Loss: 1.535274624824524, Accuracy: 1.0\n",
      "Loss: 1.5255663394927979, Accuracy: 1.0\n",
      "Loss: 1.5350399017333984, Accuracy: 1.0\n",
      "Loss: 1.5252678394317627, Accuracy: 1.0\n",
      "Loss: 1.5347578525543213, Accuracy: 1.0\n",
      "Loss: 1.5250563621520996, Accuracy: 1.0\n",
      "Loss: 1.5343759059906006, Accuracy: 1.0\n",
      "Loss: 1.524816870689392, Accuracy: 1.0\n",
      "Loss: 1.5340566635131836, Accuracy: 1.0\n",
      "Loss: 1.5245553255081177, Accuracy: 1.0\n",
      "Loss: 1.5337461233139038, Accuracy: 1.0\n",
      "Loss: 1.5243158340454102, Accuracy: 1.0\n",
      "Loss: 1.533408522605896, Accuracy: 1.0\n",
      "Loss: 1.524064540863037, Accuracy: 1.0\n",
      "Loss: 1.5330355167388916, Accuracy: 1.0\n",
      "Loss: 1.5238685607910156, Accuracy: 1.0\n",
      "Loss: 1.5327198505401611, Accuracy: 1.0\n",
      "Loss: 1.5236225128173828, Accuracy: 1.0\n",
      "Loss: 1.5323878526687622, Accuracy: 1.0\n",
      "Loss: 1.523354411125183, Accuracy: 1.0\n",
      "Loss: 1.5321769714355469, Accuracy: 1.0\n",
      "Loss: 1.523073434829712, Accuracy: 1.0\n",
      "Loss: 1.5318411588668823, Accuracy: 1.0\n",
      "Loss: 1.522786259651184, Accuracy: 1.0\n",
      "Loss: 1.531511902809143, Accuracy: 1.0\n",
      "Loss: 1.5226285457611084, Accuracy: 1.0\n",
      "Loss: 1.5308709144592285, Accuracy: 1.0\n",
      "Loss: 1.5225284099578857, Accuracy: 1.0\n",
      "Loss: 1.5305860042572021, Accuracy: 1.0\n",
      "Loss: 1.5223255157470703, Accuracy: 1.0\n",
      "Loss: 1.530311107635498, Accuracy: 1.0\n",
      "Loss: 1.5220057964324951, Accuracy: 1.0\n",
      "Loss: 1.5300617218017578, Accuracy: 1.0\n",
      "Loss: 1.5217292308807373, Accuracy: 1.0\n",
      "Loss: 1.5296821594238281, Accuracy: 1.0\n",
      "Loss: 1.52144193649292, Accuracy: 1.0\n",
      "Loss: 1.5294057130813599, Accuracy: 1.0\n",
      "Loss: 1.5211443901062012, Accuracy: 1.0\n",
      "Loss: 1.5290051698684692, Accuracy: 1.0\n",
      "Loss: 1.521073579788208, Accuracy: 1.0\n",
      "Loss: 1.5286084413528442, Accuracy: 1.0\n",
      "Loss: 1.5208076238632202, Accuracy: 1.0\n",
      "Loss: 1.5282953977584839, Accuracy: 1.0\n",
      "Loss: 1.520519495010376, Accuracy: 1.0\n",
      "Loss: 1.5280258655548096, Accuracy: 1.0\n",
      "Loss: 1.5202279090881348, Accuracy: 1.0\n",
      "Loss: 1.5277291536331177, Accuracy: 1.0\n",
      "Loss: 1.5199716091156006, Accuracy: 1.0\n",
      "Loss: 1.5273975133895874, Accuracy: 1.0\n",
      "Loss: 1.5197268724441528, Accuracy: 1.0\n",
      "Loss: 1.527101755142212, Accuracy: 1.0\n",
      "Loss: 1.519461750984192, Accuracy: 1.0\n",
      "Loss: 1.526882290840149, Accuracy: 1.0\n",
      "Loss: 1.5191824436187744, Accuracy: 1.0\n",
      "Loss: 1.526580572128296, Accuracy: 1.0\n",
      "Loss: 1.5189169645309448, Accuracy: 1.0\n",
      "Loss: 1.5263444185256958, Accuracy: 1.0\n",
      "Loss: 1.5186338424682617, Accuracy: 1.0\n",
      "Loss: 1.5261150598526, Accuracy: 1.0\n",
      "Loss: 1.5183842182159424, Accuracy: 1.0\n",
      "Loss: 1.5258417129516602, Accuracy: 1.0\n",
      "Loss: 1.5181430578231812, Accuracy: 1.0\n",
      "Loss: 1.525596261024475, Accuracy: 1.0\n",
      "Loss: 1.5179219245910645, Accuracy: 1.0\n",
      "Loss: 1.525334358215332, Accuracy: 1.0\n",
      "Loss: 1.517683744430542, Accuracy: 1.0\n",
      "Loss: 1.5250775814056396, Accuracy: 1.0\n",
      "Loss: 1.5174378156661987, Accuracy: 1.0\n",
      "Loss: 1.5248407125473022, Accuracy: 1.0\n",
      "Loss: 1.5171772241592407, Accuracy: 1.0\n",
      "Loss: 1.5245360136032104, Accuracy: 1.0\n",
      "Loss: 1.516923189163208, Accuracy: 1.0\n",
      "Loss: 1.5242849588394165, Accuracy: 1.0\n",
      "Loss: 1.516662836074829, Accuracy: 1.0\n",
      "Loss: 1.524081826210022, Accuracy: 1.0\n",
      "Loss: 1.5164436101913452, Accuracy: 1.0\n",
      "Loss: 1.5238149166107178, Accuracy: 1.0\n",
      "Loss: 1.5162127017974854, Accuracy: 1.0\n",
      "Loss: 1.5235354900360107, Accuracy: 1.0\n",
      "Loss: 1.5160006284713745, Accuracy: 1.0\n",
      "Loss: 1.5232584476470947, Accuracy: 1.0\n",
      "Loss: 1.5157725811004639, Accuracy: 1.0\n",
      "Loss: 1.523019552230835, Accuracy: 1.0\n",
      "Loss: 1.5155452489852905, Accuracy: 1.0\n",
      "Loss: 1.5227782726287842, Accuracy: 1.0\n",
      "Loss: 1.51533043384552, Accuracy: 1.0\n",
      "Loss: 1.5225138664245605, Accuracy: 1.0\n",
      "Loss: 1.5151375532150269, Accuracy: 1.0\n",
      "Loss: 1.522245168685913, Accuracy: 1.0\n",
      "Loss: 1.5149542093276978, Accuracy: 1.0\n",
      "Loss: 1.5219693183898926, Accuracy: 1.0\n",
      "Loss: 1.5147672891616821, Accuracy: 1.0\n",
      "Loss: 1.5217005014419556, Accuracy: 1.0\n",
      "Loss: 1.5145845413208008, Accuracy: 1.0\n",
      "Loss: 1.521427869796753, Accuracy: 1.0\n",
      "Loss: 1.5143433809280396, Accuracy: 1.0\n",
      "Loss: 1.5211541652679443, Accuracy: 1.0\n",
      "Loss: 1.5141370296478271, Accuracy: 1.0\n",
      "Loss: 1.520880937576294, Accuracy: 1.0\n",
      "Loss: 1.5139235258102417, Accuracy: 1.0\n",
      "Loss: 1.5205601453781128, Accuracy: 1.0\n",
      "Loss: 1.513725996017456, Accuracy: 1.0\n",
      "Loss: 1.5202629566192627, Accuracy: 1.0\n",
      "Loss: 1.5135260820388794, Accuracy: 1.0\n",
      "Loss: 1.5200341939926147, Accuracy: 1.0\n",
      "Loss: 1.5132811069488525, Accuracy: 1.0\n",
      "Loss: 1.5197945833206177, Accuracy: 1.0\n",
      "Loss: 1.513030767440796, Accuracy: 1.0\n",
      "Loss: 1.519498586654663, Accuracy: 1.0\n",
      "Loss: 1.5125757455825806, Accuracy: 1.0\n",
      "Loss: 1.5194274187088013, Accuracy: 1.0\n",
      "Loss: 1.5123236179351807, Accuracy: 1.0\n",
      "Loss: 1.5191572904586792, Accuracy: 1.0\n",
      "Loss: 1.5120553970336914, Accuracy: 1.0\n",
      "Loss: 1.5186847448349, Accuracy: 1.0\n",
      "Loss: 1.5116533041000366, Accuracy: 1.0\n",
      "Loss: 1.5182392597198486, Accuracy: 1.0\n",
      "Loss: 1.5141339302062988, Accuracy: 1.0\n",
      "Loss: 1.5180081129074097, Accuracy: 1.0\n",
      "Loss: 1.5136816501617432, Accuracy: 1.0\n",
      "Loss: 1.5174994468688965, Accuracy: 1.0\n",
      "Loss: 1.5132806301116943, Accuracy: 1.0\n",
      "Loss: 1.51724112033844, Accuracy: 1.0\n",
      "Loss: 1.5129501819610596, Accuracy: 1.0\n",
      "Loss: 1.516897439956665, Accuracy: 1.0\n",
      "Loss: 1.512575387954712, Accuracy: 1.0\n",
      "Loss: 1.516446828842163, Accuracy: 1.0\n",
      "Loss: 1.5121086835861206, Accuracy: 1.0\n",
      "Loss: 1.5161155462265015, Accuracy: 1.0\n",
      "Loss: 1.5116328001022339, Accuracy: 1.0\n",
      "Loss: 1.5158201456069946, Accuracy: 1.0\n",
      "Loss: 1.5159668922424316, Accuracy: 1.0\n",
      "Loss: 1.5211724042892456, Accuracy: 1.0\n",
      "Loss: 1.5151118040084839, Accuracy: 1.0\n",
      "Loss: 1.5197789669036865, Accuracy: 1.0\n",
      "Loss: 1.5140457153320312, Accuracy: 1.0\n",
      "Loss: 1.5209357738494873, Accuracy: 1.0\n",
      "Loss: 1.5135035514831543, Accuracy: 1.0\n",
      "Loss: 1.5204006433486938, Accuracy: 1.0\n",
      "Loss: 1.5130592584609985, Accuracy: 1.0\n",
      "Loss: 1.5198974609375, Accuracy: 1.0\n",
      "Loss: 1.512635350227356, Accuracy: 1.0\n",
      "Loss: 1.5194733142852783, Accuracy: 1.0\n",
      "Loss: 1.512205719947815, Accuracy: 1.0\n",
      "Loss: 1.5190472602844238, Accuracy: 1.0\n",
      "Loss: 1.5117374658584595, Accuracy: 1.0\n",
      "Loss: 1.5187122821807861, Accuracy: 1.0\n",
      "Loss: 1.5112950801849365, Accuracy: 1.0\n",
      "Loss: 1.5184041261672974, Accuracy: 1.0\n",
      "Loss: 1.510842204093933, Accuracy: 1.0\n",
      "Loss: 1.5180989503860474, Accuracy: 1.0\n",
      "Loss: 1.5103870630264282, Accuracy: 1.0\n",
      "Loss: 1.5177843570709229, Accuracy: 1.0\n",
      "Loss: 1.509919285774231, Accuracy: 1.0\n",
      "Loss: 1.5174765586853027, Accuracy: 1.0\n",
      "Loss: 1.5094528198242188, Accuracy: 1.0\n",
      "Loss: 1.5171798467636108, Accuracy: 1.0\n",
      "Loss: 1.5089138746261597, Accuracy: 1.0\n",
      "Loss: 1.5168265104293823, Accuracy: 1.0\n",
      "Loss: 1.508379578590393, Accuracy: 1.0\n",
      "Loss: 1.5163630247116089, Accuracy: 1.0\n",
      "Loss: 1.5078226327896118, Accuracy: 1.0\n",
      "Loss: 1.5158785581588745, Accuracy: 1.0\n",
      "Loss: 1.5073062181472778, Accuracy: 1.0\n",
      "Loss: 1.5154550075531006, Accuracy: 1.0\n",
      "Loss: 1.5068098306655884, Accuracy: 1.0\n",
      "Loss: 1.5150436162948608, Accuracy: 1.0\n",
      "Loss: 1.5063166618347168, Accuracy: 1.0\n",
      "Loss: 1.5147063732147217, Accuracy: 1.0\n",
      "Loss: 1.5055609941482544, Accuracy: 1.0\n",
      "Loss: 1.5151065587997437, Accuracy: 1.0\n",
      "Loss: 1.504869818687439, Accuracy: 1.0\n",
      "Loss: 1.5140727758407593, Accuracy: 1.0\n",
      "Loss: 1.5038964748382568, Accuracy: 1.0\n",
      "Loss: 1.5155010223388672, Accuracy: 1.0\n",
      "Loss: 1.5029925107955933, Accuracy: 1.0\n",
      "Loss: 1.5147383213043213, Accuracy: 1.0\n",
      "Loss: 1.5023800134658813, Accuracy: 1.0\n",
      "Loss: 1.5146318674087524, Accuracy: 1.0\n",
      "Loss: 1.5017149448394775, Accuracy: 1.0\n",
      "Loss: 1.515668511390686, Accuracy: 1.0\n",
      "Loss: 1.5010242462158203, Accuracy: 1.0\n",
      "Loss: 1.5165410041809082, Accuracy: 1.0\n",
      "Loss: 1.5032479763031006, Accuracy: 1.0\n",
      "Loss: 1.5172451734542847, Accuracy: 1.0\n",
      "Loss: 1.5025970935821533, Accuracy: 1.0\n",
      "Loss: 1.5165913105010986, Accuracy: 1.0\n",
      "Loss: 1.5023868083953857, Accuracy: 1.0\n",
      "Loss: 1.5164997577667236, Accuracy: 1.0\n",
      "Loss: 1.5016056299209595, Accuracy: 1.0\n",
      "Loss: 1.517398476600647, Accuracy: 1.0\n",
      "Loss: 1.5009393692016602, Accuracy: 1.0\n",
      "Loss: 1.5167014598846436, Accuracy: 1.0\n",
      "Loss: 1.5008442401885986, Accuracy: 1.0\n",
      "Loss: 1.5163640975952148, Accuracy: 1.0\n",
      "Loss: 1.5000909566879272, Accuracy: 1.0\n",
      "Loss: 1.5173496007919312, Accuracy: 1.0\n",
      "Loss: 1.4994617700576782, Accuracy: 1.0\n",
      "Loss: 1.516890525817871, Accuracy: 1.0\n",
      "Loss: 1.498937964439392, Accuracy: 1.0\n",
      "Loss: 1.5175971984863281, Accuracy: 1.0\n",
      "Loss: 1.4986469745635986, Accuracy: 1.0\n",
      "Loss: 1.5173929929733276, Accuracy: 1.0\n",
      "Loss: 1.4982528686523438, Accuracy: 1.0\n",
      "Loss: 1.5177052021026611, Accuracy: 1.0\n",
      "Loss: 1.4973938465118408, Accuracy: 1.0\n",
      "Loss: 1.5188148021697998, Accuracy: 1.0\n",
      "Loss: 1.4970086812973022, Accuracy: 1.0\n",
      "Loss: 1.5184640884399414, Accuracy: 1.0\n",
      "Loss: 1.4967143535614014, Accuracy: 1.0\n",
      "Loss: 1.518074631690979, Accuracy: 1.0\n",
      "Loss: 1.4964663982391357, Accuracy: 1.0\n",
      "Loss: 1.5177011489868164, Accuracy: 1.0\n",
      "Loss: 1.4961862564086914, Accuracy: 1.0\n",
      "Loss: 1.517369031906128, Accuracy: 1.0\n",
      "Loss: 1.4959651231765747, Accuracy: 1.0\n",
      "Loss: 1.5168931484222412, Accuracy: 1.0\n",
      "Loss: 1.4956810474395752, Accuracy: 1.0\n",
      "Loss: 1.5164738893508911, Accuracy: 1.0\n",
      "Loss: 1.495424509048462, Accuracy: 1.0\n",
      "Loss: 1.5164735317230225, Accuracy: 1.0\n",
      "Loss: 1.4950975179672241, Accuracy: 1.0\n",
      "Loss: 1.5163606405258179, Accuracy: 1.0\n",
      "Loss: 1.494807481765747, Accuracy: 1.0\n",
      "Loss: 1.5163334608078003, Accuracy: 1.0\n",
      "Loss: 1.494478702545166, Accuracy: 1.0\n",
      "Loss: 1.5163289308547974, Accuracy: 1.0\n",
      "Loss: 1.4941486120224, Accuracy: 1.0\n",
      "Loss: 1.5164411067962646, Accuracy: 1.0\n",
      "Loss: 1.4937989711761475, Accuracy: 1.0\n",
      "Loss: 1.516272783279419, Accuracy: 1.0\n",
      "Loss: 1.493464708328247, Accuracy: 1.0\n",
      "Loss: 1.5162980556488037, Accuracy: 1.0\n",
      "Loss: 1.4931466579437256, Accuracy: 1.0\n",
      "Loss: 1.5163300037384033, Accuracy: 1.0\n",
      "Loss: 1.4929027557373047, Accuracy: 1.0\n",
      "Loss: 1.5160126686096191, Accuracy: 1.0\n",
      "Loss: 1.492668867111206, Accuracy: 1.0\n",
      "Loss: 1.5158882141113281, Accuracy: 1.0\n",
      "Loss: 1.492349624633789, Accuracy: 1.0\n",
      "Loss: 1.5156850814819336, Accuracy: 1.0\n",
      "Loss: 1.4920752048492432, Accuracy: 1.0\n",
      "Loss: 1.5154527425765991, Accuracy: 1.0\n",
      "Loss: 1.4916270971298218, Accuracy: 1.0\n",
      "Loss: 1.5157272815704346, Accuracy: 1.0\n",
      "Loss: 1.4913049936294556, Accuracy: 1.0\n",
      "Loss: 1.5158238410949707, Accuracy: 1.0\n",
      "Loss: 1.4906127452850342, Accuracy: 1.0\n",
      "Loss: 1.5163899660110474, Accuracy: 1.0\n",
      "Loss: 1.490327000617981, Accuracy: 1.0\n",
      "Loss: 1.516087532043457, Accuracy: 1.0\n",
      "Loss: 1.4901288747787476, Accuracy: 1.0\n",
      "Loss: 1.5157145261764526, Accuracy: 1.0\n",
      "Loss: 1.489928960800171, Accuracy: 1.0\n",
      "Loss: 1.5154750347137451, Accuracy: 1.0\n",
      "Loss: 1.4896063804626465, Accuracy: 1.0\n",
      "Loss: 1.5156571865081787, Accuracy: 1.0\n",
      "Loss: 1.4890379905700684, Accuracy: 1.0\n",
      "Loss: 1.516089677810669, Accuracy: 1.0\n",
      "Loss: 1.4888030290603638, Accuracy: 1.0\n",
      "Loss: 1.5157506465911865, Accuracy: 1.0\n",
      "Loss: 1.4885808229446411, Accuracy: 1.0\n",
      "Loss: 1.5153746604919434, Accuracy: 1.0\n",
      "Loss: 1.4884073734283447, Accuracy: 1.0\n",
      "Loss: 1.5149993896484375, Accuracy: 1.0\n",
      "Loss: 1.4882363080978394, Accuracy: 1.0\n",
      "Loss: 1.5146173238754272, Accuracy: 1.0\n",
      "Loss: 1.4884459972381592, Accuracy: 1.0\n",
      "Loss: 1.5139877796173096, Accuracy: 1.0\n",
      "Loss: 1.4882131814956665, Accuracy: 1.0\n",
      "Loss: 1.513800024986267, Accuracy: 1.0\n",
      "Loss: 1.4877052307128906, Accuracy: 1.0\n",
      "Loss: 1.5145190954208374, Accuracy: 1.0\n",
      "Loss: 1.4873067140579224, Accuracy: 1.0\n",
      "Loss: 1.5141489505767822, Accuracy: 1.0\n",
      "Loss: 1.4871065616607666, Accuracy: 1.0\n",
      "Loss: 1.5137569904327393, Accuracy: 1.0\n",
      "Loss: 1.4868122339248657, Accuracy: 1.0\n",
      "Loss: 1.5139750242233276, Accuracy: 1.0\n",
      "Loss: 1.4866163730621338, Accuracy: 1.0\n",
      "Loss: 1.5138061046600342, Accuracy: 1.0\n",
      "Loss: 1.486345887184143, Accuracy: 1.0\n",
      "Loss: 1.513785481452942, Accuracy: 1.0\n",
      "Loss: 1.4859611988067627, Accuracy: 1.0\n",
      "Loss: 1.5136221647262573, Accuracy: 1.0\n",
      "Loss: 1.4858372211456299, Accuracy: 1.0\n",
      "Loss: 1.5131762027740479, Accuracy: 1.0\n",
      "Loss: 1.4856889247894287, Accuracy: 1.0\n",
      "Loss: 1.5128744840621948, Accuracy: 1.0\n",
      "Loss: 1.4853928089141846, Accuracy: 1.0\n",
      "Loss: 1.5128662586212158, Accuracy: 1.0\n",
      "Loss: 1.485314965248108, Accuracy: 1.0\n",
      "Loss: 1.51221764087677, Accuracy: 1.0\n",
      "Loss: 1.4851045608520508, Accuracy: 1.0\n",
      "Loss: 1.5120973587036133, Accuracy: 1.0\n",
      "Loss: 1.484900951385498, Accuracy: 1.0\n",
      "Loss: 1.511731743812561, Accuracy: 1.0\n",
      "Loss: 1.4846974611282349, Accuracy: 1.0\n",
      "Loss: 1.5115758180618286, Accuracy: 1.0\n",
      "Loss: 1.486430048942566, Accuracy: 1.0\n",
      "Loss: 1.5109049081802368, Accuracy: 1.0\n",
      "Loss: 1.4860106706619263, Accuracy: 1.0\n",
      "Loss: 1.5123244524002075, Accuracy: 1.0\n",
      "Loss: 1.4859646558761597, Accuracy: 1.0\n",
      "Loss: 1.5118653774261475, Accuracy: 1.0\n",
      "Loss: 1.4857919216156006, Accuracy: 1.0\n",
      "Loss: 1.5114567279815674, Accuracy: 1.0\n",
      "Loss: 1.485762357711792, Accuracy: 1.0\n",
      "Loss: 1.511029601097107, Accuracy: 1.0\n",
      "Loss: 1.4856549501419067, Accuracy: 1.0\n",
      "Loss: 1.5107042789459229, Accuracy: 1.0\n",
      "Loss: 1.485512614250183, Accuracy: 1.0\n",
      "Loss: 1.510478138923645, Accuracy: 1.0\n",
      "Loss: 1.485390305519104, Accuracy: 1.0\n",
      "Loss: 1.51018226146698, Accuracy: 1.0\n",
      "Loss: 1.4853368997573853, Accuracy: 1.0\n",
      "Loss: 1.509796380996704, Accuracy: 1.0\n",
      "Loss: 1.485266923904419, Accuracy: 1.0\n",
      "Loss: 1.5095200538635254, Accuracy: 1.0\n",
      "Loss: 1.485145092010498, Accuracy: 1.0\n",
      "Loss: 1.5093202590942383, Accuracy: 1.0\n",
      "Loss: 1.48495614528656, Accuracy: 1.0\n",
      "Loss: 1.5093683004379272, Accuracy: 1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1000\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m dataloader:\n\u001b[0;32m----> 4\u001b[0m         model\u001b[39m.\u001b[39;49mtrain(x, y)\n",
      "File \u001b[0;32m~/Documents/tufts/academic/cs_137/project/dnns_project/python/model.py:61\u001b[0m, in \u001b[0;36mCNN.train\u001b[0;34m(self, x, y, lr, epochs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39m# for epoch in range(epochs):\u001b[39;00m\n\u001b[1;32m     60\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 61\u001b[0m y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(x)\n\u001b[1;32m     62\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss(y_pred, y)\n\u001b[1;32m     63\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Documents/tufts/academic/cs_137/project/dnns_project/python/model.py:34\u001b[0m, in \u001b[0;36mCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(x\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m     33\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mforward(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/dnns_project/lib/python3.8/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/dnns_project/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/dnns_project/lib/python3.8/site-packages/torch/nn/modules/pooling.py:166\u001b[0m, in \u001b[0;36mMaxPool2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor):\n\u001b[0;32m--> 166\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mmax_pool2d(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel_size, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    167\u001b[0m                         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, ceil_mode\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mceil_mode,\n\u001b[1;32m    168\u001b[0m                         return_indices\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreturn_indices)\n",
      "File \u001b[0;32m~/miniconda3/envs/dnns_project/lib/python3.8/site-packages/torch/_jit_internal.py:485\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m if_true(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    484\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 485\u001b[0m     \u001b[39mreturn\u001b[39;00m if_false(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/dnns_project/lib/python3.8/site-packages/torch/nn/functional.py:782\u001b[0m, in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[39mif\u001b[39;00m stride \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    781\u001b[0m     stride \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mannotate(List[\u001b[39mint\u001b[39m], [])\n\u001b[0;32m--> 782\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mmax_pool2d(\u001b[39minput\u001b[39;49m, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model\n",
    "for i in range(1000):\n",
    "    for x, y in dataloader:\n",
    "        model.train(x, y)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnns_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "985e63cb0891e9537b8543a3aa66c73eddef83a644a58110e14736c31342c50a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
